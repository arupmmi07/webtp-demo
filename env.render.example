# Environment Variables for Render.com Deployment
# Copy these to Render Dashboard → Environment Variables
# DO NOT commit actual values to Git!

# ============================================
# Python Configuration
# ============================================
PYTHON_VERSION=3.11.0

# ============================================
# Application Settings
# ============================================
PORT=8000
HOST=0.0.0.0
APP_BASE_URL=https://webpt-api.onrender.com  # Auto-set by Render

# ============================================
# LLM Configuration
# ============================================
# Set to 'true' for demo mode (no API keys needed)
# Set to 'false' for production AI
USE_MOCK_LLM=false

# Cannot use local models on Render (cloud deployment)
USE_LOCAL_MODEL=false

# ============================================
# API Keys (Set in Render Dashboard)
# ============================================
# Option 1: Use Claude (Anthropic)
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxxxxxxxxx

# Option 2: Use OpenAI GPT
OPENAI_API_KEY=sk-xxxxxxxxxxxxx

# Option 3: Use Azure OpenAI
AZURE_API_KEY=your-azure-key
AZURE_API_BASE=https://your-instance.openai.azure.com/
AZURE_API_VERSION=2024-02-15-preview
AZURE_DEPLOYMENT_NAME=your-deployment

# ============================================
# LiteLLM Configuration (Optional)
# ============================================
LITELLM_BASE_URL=https://api.openai.com/v1
LITELLM_API_KEY=sk-xxxxxxxxxxxxx
LITELLM_DEFAULT_MODEL=gpt-3.5-turbo

# ============================================
# Langfuse Observability (Optional)
# ============================================
LANGFUSE_PUBLIC_KEY=pk-lf-xxxxxxxxxxxxx
LANGFUSE_SECRET_KEY=sk-lf-xxxxxxxxxxxxx
LANGFUSE_HOST=https://cloud.langfuse.com

# ============================================
# Database (Auto-set by Render)
# ============================================
# DATABASE_URL=postgresql://user:pass@host:5432/dbname
# This is automatically set when you add a PostgreSQL database

# ============================================
# CORS Settings
# ============================================
# Comma-separated list of allowed origins
# In production, set to your actual domains
ALLOWED_ORIGINS=*

# For production with custom domains:
# ALLOWED_ORIGINS=https://app.yourdomain.com,https://api.yourdomain.com

# ============================================
# Streamlit UI Settings (for webpt-ui service)
# ============================================
API_BASE_URL=https://webpt-api.onrender.com  # Auto-set by Render
STREAMLIT_SERVER_HEADLESS=true
STREAMLIT_SERVER_PORT=8501
STREAMLIT_BROWSER_GATHER_USAGE_STATS=false

# ============================================
# Redis Cache (Optional - if you add Redis)
# ============================================
# REDIS_URL=redis://user:pass@host:6379
# Auto-set by Render if you add Redis service

# ============================================
# Monitoring & Logging
# ============================================
LOG_LEVEL=INFO

# ============================================
# Feature Flags (Optional)
# ============================================
# Enable/disable features
ENABLE_BACKFILL_AGENT=true
ENABLE_EMAIL_NOTIFICATIONS=true
ENABLE_SMS_NOTIFICATIONS=false

# ============================================
# Cost Limits (Optional)
# ============================================
DAILY_COST_LIMIT=5.00
MONTHLY_COST_LIMIT=150.00

# ============================================
# Notes for Render Deployment
# ============================================
# 
# 1. Set secrets in Render Dashboard, not in render.yaml:
#    Dashboard → Service → Environment → Add Environment Variable
#
# 2. Use Environment Groups for shared secrets:
#    Dashboard → Environment Groups → Create Group
#    Then link to multiple services
#
# 3. Auto-set variables (don't manually set these):
#    - PORT (Render sets this)
#    - DATABASE_URL (auto-set when database added)
#    - APP_BASE_URL (auto-set to service URL)
#
# 4. For different environments:
#    - Development: USE_MOCK_LLM=true
#    - Staging: USE_MOCK_LLM=false + cheap model (gpt-3.5-turbo)
#    - Production: USE_MOCK_LLM=false + best model (claude-3-sonnet)
#

