# ğŸ¥ Therapist Replacement System

**Automated provider matching powered by AI agents**

When a therapist calls in sick, this system automatically finds the best replacement and reschedules appointments using intelligent matching algorithms.

---

## ğŸš€ Quick Start

### Option 1: Cloud Deploy (Render.com) - **Recommended for Production** â˜ï¸

```bash
# Deploy to Render.com in 5 minutes
# See: RENDER_QUICK_START.md

1. Push code to GitHub
2. Connect to Render.com
3. Auto-deploy from render.yaml
4. Access at: https://webtp-ui.onrender.com
```

**Free tier available!** Perfect for demos and production.  
ğŸ“– **[Complete Render Deploy Guide â†’](./RENDER_QUICK_START.md)**

### Option 2: Docker (Local Development - Includes LiteLLM)

```bash
# Start all services (API + UI + LiteLLM)
make docker-up

# Access UI at http://localhost:8501
# Access LiteLLM at http://localhost:4000
```

### Option 3: Local Development

```bash
# Start API and UI locally
make dev

# Opens at http://localhost:8501
```

### Option 4: CLI

```bash
make cli
```

Traditional command-line interface for automation/scripts.

---

## ğŸ“¦ Installation

```bash
# Install dependencies
make install

# Or manually
pip3 install -r requirements.txt
```

---

## ğŸ¯ Demo It!

**In the UI:**
1. Run: `make dev`
2. Type: `therapist departed T001`
3. Watch the workflow execute!

**In the CLI:**
1. Run: `make cli`
2. Type: `therapist departed T001`
3. See the results!

---

## ğŸ“‹ Available Commands

```bash
make help          # Show all commands

# Docker (Recommended)
make docker-up       # ğŸ³ Start all services (API + UI + LiteLLM)
make docker-down     # ğŸ›‘ Stop all services
make docker-logs     # ğŸ“‹ View logs
make docker-restart  # ğŸ”„ Restart services
make docker-clean    # ğŸ§¹ Clean Docker resources

# Local Development
make dev           # ğŸš€ Launch Chat UI + API locally
make cli           # ğŸ’» Launch CLI
make install       # ğŸ“¦ Install dependencies

# Testing
make test          # ğŸ§ª Run all tests

# Utilities
make clean         # ğŸ§¹ Clean cache
make clean-all     # ğŸ—‘ï¸ Remove venv + cache
```

---

## ğŸ¬ What This Demo Does

### Scenario
Dr. Sarah Johnson (T001) calls in sick. The system automatically:

1. **ğŸš¨ Trigger** - Identifies affected appointments (Maria Rodriguez)
2. **ğŸ” Filtering** - Eliminates unqualified providers (P003: too far)
3. **â­ Scoring** - Ranks providers using 5 factors (150 points max)
   - Dr. Emily Ross: **75 points** (EXCELLENT)
   - Dr. Michael Lee: **48 points** (ACCEPTABLE)
4. **ğŸ’¬ Consent** - Gets patient approval via SMS
5. **ğŸ“… Booking** - Confirms with Dr. Ross on Tuesday 11/20 at 10 AM
6. **ğŸ“Š Audit** - Generates complete log

### Winner
**Dr. Emily Ross** wins because:
- âœ… Perfect orthopedic specialty match (35/35 pts)
- âœ… Female provider matching preference (30/30 pts)
- âœ… Tuesday 10 AM exact time match (20/20 pts)
- âœ… Good availability at 60% capacity (10/25 pts)

---

## ğŸ­ Three Modes Available

### Option 1: Mock Mode (Default) - **$0/month**
- ğŸŸ¡ Hardcoded LLM responses
- âœ… Perfect for initial demos
- âœ… No setup needed
```bash
make docker-up
```

### Option 2: Local Model (LM Studio) - **$0/month** â­ NEW
- âœ… **FREE** - No API costs!
- âœ… Private - data stays on your machine
- âœ… Fast (with GPU)
- ğŸ“š Best for development & testing

```bash
# 1. Download LM Studio: https://lmstudio.ai
# 2. Start server (port 1234)
# 3. Configure
bash scripts/setup-env.sh
nano .env
# Set: USE_MOCK_LLM=false
# Set: USE_LOCAL_MODEL=true

# 4. Start
make docker-up
```

**See:** `docs/LM_STUDIO_SETUP.md` for complete guide

### Option 3: Cloud API (Anthropic/OpenAI) - **$50-150/month**
- âœ… Best quality
- âœ… No hardware needed
- âœ… Very fast
- âš ï¸ Costs money (budget-protected at $5/day)

```bash
# 1. Get API key: https://console.anthropic.com
# 2. Configure
bash scripts/setup-env.sh
nano .env
# Set: ANTHROPIC_API_KEY=sk-ant-api03-...
# Set: USE_MOCK_LLM=false
# Set: USE_LOCAL_MODEL=false

# 3. Start
make docker-up
```

**LiteLLM Features:**
- âœ… Unified API for all providers
- âœ… Auto fallbacks (local â†’ Claude â†’ GPT-4)
- âœ… Cost tracking ($5/day limit)
- âœ… Request caching
- âœ… Rate limiting

**Recommended Strategy:**
- **Dev/Testing**: Local models (FREE)
- **Staging**: Claude Haiku ($10-20/month)
- **Production**: Claude Sonnet ($50-150/month)

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ chat_ui.py          # Streamlit web UI â­ NEW
â”‚   â”œâ”€â”€ cli.py              # CLI interface
â”‚   â””â”€â”€ mock_data.py        # Test data
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ smart_scheduling_agent.py
â”‚   â””â”€â”€ patient_engagement_agent.py
â”œâ”€â”€ mcp_servers/
â”‚   â”œâ”€â”€ knowledge/          # Rules & policies
â”‚   â””â”€â”€ domain/             # Patient/provider APIs
â”œâ”€â”€ adapters/
â”‚   â””â”€â”€ llm/
â”‚       â”œâ”€â”€ mock_llm.py     # Mocked LLM
â”‚       â””â”€â”€ litellm_adapter.py  # Real LLM (future)
â”œâ”€â”€ orchestrator/
â”‚   â””â”€â”€ workflow.py         # 6-stage workflow
â”œâ”€â”€ docs/                   # ğŸ“š Complete documentation
â”‚   â”œâ”€â”€ UI_QUICKSTART.md
â”‚   â”œâ”€â”€ MOCKS.md
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Makefile               # ğŸ”§ Easy commands
â””â”€â”€ requirements.txt       # Python dependencies
```

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| **`RENDER_QUICK_START.md`** | 5-minute Render.com deployment â­ NEW |
| **`RENDER_DEPLOYMENT.md`** | Complete Render deployment guide â­ NEW |
| **`docs/LM_STUDIO_SETUP.md`** | Use FREE local models (LM Studio) |
| **`docker/README.md`** | Docker deployment guide |
| **`DOCKER_SETUP.md`** | Quick Docker + LiteLLM setup |
| **`config/cost_limits.yaml`** | Detailed cost breakdown |
| **`docs/UI_QUICKSTART.md`** | How to use the web UI |
| **`docs/MOCKS.md`** | What's mocked & how to swap |
| **`DEMO_GUIDE.md`** | Patient email simulation guide |
| **`DEMO_STORY.md`** | Simple demo narrative |
| **`docs/LANGGRAPH_EXPLAINED.md`** | LangGraph workflow explanation |
| **`docs/USE_CASES_SIMPLIFIED.md`** | 6 use cases (current demo) â­ |
| **`docs/USE_CASES.md`** | 6 use cases (full vision) |

---

## ğŸ”„ Next Steps

### Immediate (5 minutes)
```bash
# Option A: Docker (includes LiteLLM)
make docker-up

# Option B: Local development
make install && make dev
```

### Week 1 (Swap to Real LLM) - **~2 hours**
```bash
# 1. Get Anthropic API key
# Sign up at https://console.anthropic.com

# 2. Configure .env
cp .env.example .env
# Add: ANTHROPIC_API_KEY=sk-ant-api03-...

# 3. Start with real LLM
USE_MOCK_LLM=false make docker-up

# 4. Test
# Type: "therapist departed T001"
# Watch real Claude AI make decisions!
```

**Benefits:**
- âœ… Real AI decision making
- âœ… Adapts to complex scenarios
- âœ… No hardcoded logic
- âœ… Better than rule-based systems

### Week 2-4 (Production Ready) - **~3 weeks**
- [ ] Add PDF parsing for compliance documents
- [ ] Connect to WebPT API / database
- [ ] Add real SMS/email (Twilio/SendGrid)
- [ ] Add authentication (OAuth)
- [ ] Deploy to cloud (AWS/Azure/GCP)
- [ ] Add monitoring (Prometheus/Grafana)

See `docker/README.md` for deployment guide.

---

## ğŸ¨ UI vs CLI

### Web UI (Streamlit) - **Recommended for Demos**
- âœ… Modern ChatGPT-like interface
- âœ… Visual workflow stages with tabs
- âœ… Interactive tables for scores
- âœ… Export to JSON
- âœ… Sidebar with quick commands
- âœ… Perfect for stakeholder demos

### CLI - **Good for Automation**
- âœ… Terminal-based
- âœ… Scriptable
- âœ… Good for CI/CD
- âœ… Lower resource usage

**Both interfaces use the same backend!**

---

## ğŸ§ª Testing

```bash
# Test all components
make test-all-components

# Test individual pieces
make test-agents      # Smart Scheduling & Patient Engagement agents
make test-workflow    # Workflow orchestrator
make test-mcp         # MCP servers

# Validate everything
make validate
```

All tests should pass! âœ…

---

## ğŸ’° Cost Comparison

| Mode | Setup | Per Workflow | Monthly (100 workflows/day) |
|------|-------|--------------|----------------------------|
| **Mock** | None | $0 | $0 |
| **Local Model** â­ | LM Studio | $0 | **$0** |
| **Cloud API** | API key | $0.035 | $50-150 (budget-protected) |

### Local Model (LM Studio) - FREE!
- âœ… **$0/month** - No API costs
- âœ… Unlimited workflows
- âœ… 100% private
- âš ï¸ Requires good computer (8GB+ RAM, GPU recommended)

### Cloud API (Budget-Protected)
- **Hard cap**: $5/day (enforced by LiteLLM)
- **Max monthly**: $150 (30 days Ã— $5)
- **Typical**: $50-75/month (50-100 workflows/day)
- **Alert**: $4/day (80% threshold)

**Daily Usage:**
- 10 workflows = $0.35/day = ~$10/month
- 50 workflows = $1.75/day = ~$50/month  
- 100 workflows = $3.50/day = ~$100/month
- 140+ workflows = Budget limit hit

**Full Stack (Production):**
- LLM: $0 (local) or $50-150 (cloud)
- Database: ~$25 (Supabase)
- SMS/Email: ~$50 (Twilio/SendGrid)
- **Total**: $75-225/month

See `config/cost_limits.yaml` for detailed breakdown.

---

## ğŸ› Troubleshooting

### Issue: `make dev` fails

```bash
# Solution: Install Streamlit
make install

# Or manually
pip3 install streamlit plotly
```

### Issue: Python version

```bash
# Requires Python 3.9+
python3 --version

# Check system status
make status
```

### Issue: Port already in use

```bash
# Use different port
streamlit run demo/chat_ui.py --server.port 8502
```

---

## ğŸ¤ Contributing

This is a demo/prototype system. Future enhancements:
- [ ] Add more test scenarios
- [ ] Add real PDF parsing
- [ ] Connect to real database
- [ ] Add authentication
- [ ] Deploy to cloud

---

## ğŸ“ Support

**Questions?**
1. Read `docs/UI_QUICKSTART.md` for UI help
2. Read `docs/MOCKS.md` for mock swapping
3. Run `make help` for all commands

---

## âš¡ TL;DR

### Quick Start (Docker)
```bash
# Start everything (API + UI + LiteLLM)
make docker-up

# Open browser
open http://localhost:8501

# Type command
therapist departed T001

# ğŸ‰ Watch it work!
```

### Quick Start (Local)
```bash
# Install
make install

# Run UI + API
make dev

# Try it
therapist departed T001
```

---

**Built with:** LangGraph + Streamlit + LiteLLM + MCP  
**Architecture:** Modular, vendor-agnostic, production-ready  
**Timeline:** 5 min (demo) â†’ 2 hours (real LLM) â†’ 3 weeks (production)  
**Cost:** $0 (mocks) â†’ $50-75/month (LLM) â†’ $125-150/month (full stack)  
**Budget:** **$5/day hard limit** (protected by LiteLLM)

ğŸš€ **Ready to demo!** ğŸ³ **Docker-ready!** ğŸ’° **Budget-protected!**

