# Prompt Architecture Validation

> **Date:** 2025-11-20  
> **Goal:** Validate completeness, correctness, and simplicity

---

## ğŸ” Current Prompt Inventory

| Prompt Name | Purpose | Used Where? | Priority |
|-------------|---------|-------------|----------|
| `healthcare-chat-router-v1` | Parse user messages | Chat UI entry | âœ… CRITICAL |
| `healthcare-intent-classifier-v1` | Classify intent only | Alternative to router | âš ï¸ REDUNDANT |
| `healthcare-entity-extractor-v1` | Extract entities only | Alternative to router | âš ï¸ REDUNDANT |
| `provider-scoring-prompt-v1` | Score/rank providers | Smart Scheduling Agent | âœ… CRITICAL |
| `patient-engagement-message-v1` | Generate patient messages | Patient Engagement Agent | âœ… CRITICAL |

---

## ğŸ“Š System Flow Analysis

### 1. Chat Entry Point (User â†’ System)

**Current:**
```
User types: "therapist departed T001"
   â†“
[Pattern matching - hardcoded]
   â†“
Extract provider ID
   â†“
Trigger workflow
```

**With LLM:**
```
User types: "Sarah called in sick" / "T001 unavailable" / "therapist departed T001"
   â†“
[LLM: chat-router] âœ…
   â†“
Structured JSON: {intent, entities, action}
   â†“
Trigger workflow
```

**Prompt Needed:** âœ… `chat-router` (HAVE IT)

---

### 2. Provider Filtering (Compliance Check)

**Current:**
```python
def filter_candidates(patient_id, appointment_id, candidate_ids):
    # Simple logic: check specialty, status
    # Uses knowledge base for rules
```

**Question:** Do we need LLM here?

**Analysis:**
- Simple rules (specialty match, active status) â†’ No LLM needed
- Complex rules (Medicare POC validation, payer rules) â†’ Could use LLM

**Recommendation:** 
- Start WITHOUT LLM (current logic is fine)
- Add `compliance-checker-v1` prompt ONLY if rules become too complex

**Prompt Needed:** âŒ NOT CRITICAL (future enhancement)

---

### 3. Provider Scoring (Smart Matching)

**Current:**
```python
def score_and_rank_providers(patient_id, appointment_id, qualified_provider_ids):
    # Multi-factor scoring:
    # - Continuity, specialty, location, capacity, preferences
```

**With LLM:**
```
Factors: continuity, specialty, location, capacity, preferences
   â†“
[LLM: provider-scoring] âœ…
   â†“
Scored & ranked providers with reasoning
```

**Prompt Needed:** âœ… `provider-scoring` (HAVE IT)

---

### 4. Patient Communication

**Current:**
```python
def send_offer(patient_id, appointment_id, new_provider_id, date, time):
    # Template-based message
    message = f"Hi {patient_name}, Dr. {provider_name} is available..."
```

**With LLM:**
```
Context: patient, provider, appointment
   â†“
[LLM: patient-message] âœ…
   â†“
Personalized, empathetic message
```

**Prompt Needed:** âœ… `patient-message` (HAVE IT)

---

### 5. Patient Response Parsing

**Current:**
```python
# URL-based: /patient-response?token=xxx&response=yes
# Simple: "yes" or "no"
```

**Question:** Do we need LLM?

**Analysis:**
- Simple responses ("yes", "no") â†’ Regex is fine
- Complex responses ("can I get more info?", "what time?") â†’ LLM helpful

**Recommendation:**
- Start WITHOUT LLM (current URL-based is fine)
- Add `patient-response-parser-v1` if we add conversational replies

**Prompt Needed:** âŒ NOT CRITICAL (future enhancement)

---

### 6. Query Handling (Receptionist Questions)

**Examples:**
- "show waitlist"
- "what's Maria's appointment status?"
- "who's on call today?"

**Current:** Not implemented

**With LLM:**
```
User: "show waitlist"
   â†“
[LLM: query-handler] âŒ MISSING
   â†“
{intent: "QUERY_WAITLIST", action: "get_waitlist"}
```

**Prompt Needed:** âš ï¸ `query-handler-v1` (MISSING - but covered by chat-router)

---

## ğŸ¯ Architecture Assessment

### âŒ ISSUE 1: Redundancy

We have **3 prompts** that do similar things:

1. **chat-router** - Does intent + entity extraction together
2. **intent-classifier** - Just intent
3. **entity-extractor** - Just entities

**Problem:** This is redundant and confusing.

**Options:**

#### Option A: Use Only Chat Router (RECOMMENDED)
```
User message â†’ [chat-router] â†’ {intent, entities, action}
```
âœ… Simple, one LLM call
âœ… Fastest
âœ… Easiest to maintain

#### Option B: Use Pipeline
```
User message â†’ [intent-classifier] â†’ [entity-extractor] â†’ {intent, entities}
```
âŒ Two LLM calls (slower, more expensive)
âœ… More modular (can optimize each separately)

#### Option C: Hybrid
```
User message â†’ [chat-router] (fast path)
If ambiguous â†’ [entity-extractor] (clarification)
```
âœ… Best of both worlds
âš ï¸ More complex

**RECOMMENDATION:** Go with **Option A** (chat-router only)
- Simpler architecture
- Faster (1 LLM call vs 2)
- Cheaper
- Add specialized prompts ONLY when needed

---

### âŒ ISSUE 2: Missing Prompts

Based on system flow, we're missing:

1. **Clarification Generator** (When ambiguous)
   ```
   User: "Sarah is sick"
   System: "I found Dr. Sarah Johnson (T001) and Sarah Miller (PAT004). Which?"
   ```
   
2. **Query Response** (Already covered by chat-router!)
   ```
   User: "show waitlist"
   [chat-router detects QUERY_WAITLIST intent]
   ```

**RECOMMENDATION:** 
- Add `clarification-generator-v1` for ambiguity handling
- Query handling already covered by chat-router âœ…

---

## âœ… REVISED PROMPT ARCHITECTURE (SIMPLIFIED)

### Core Prompts (Must Have)

| # | Prompt | Purpose | When Used |
|---|--------|---------|-----------|
| 1 | `healthcare-chat-router-v1` | Parse all user messages | Every chat message |
| 2 | `provider-scoring-prompt-v1` | Score/rank providers | Provider matching |
| 3 | `patient-engagement-message-v1` | Generate patient messages | Patient communication |

**Total: 3 prompts** (down from 5) âœ…

---

### Optional Prompts (Add When Needed)

| # | Prompt | Purpose | Priority |
|---|--------|---------|----------|
| 4 | `clarification-generator-v1` | Handle ambiguity | LOW (add later) |
| 5 | `compliance-checker-v1` | Complex rule interpretation | LOW (current logic is fine) |
| 6 | `patient-response-parser-v1` | Parse conversational replies | LOW (URL-based works) |

---

## ğŸ—ï¸ SIMPLIFIED ARCHITECTURE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CHAT UI                                                â”‚
â”‚  "Sarah is sick" / "therapist departed T001"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
         [LLM: chat-router] â† SINGLE ENTRY POINT
                  â”‚
                  â†“
         {intent, entities, action}
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                 â†“                â†“
   THERAPIST_         QUERY_          PATIENT_
   UNAVAILABLE        STATUS          DECLINED
         â”‚                 â”‚                â”‚
         â†“                 â†“                â†“
   Trigger            Get Data        Backfill
   Workflow          Return JSON      Workflow
         â”‚
         â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Smart Scheduling Agent                 â”‚
   â”‚  1. Filter (no LLM - simple logic)      â”‚
   â”‚  2. Score [LLM: provider-scoring] âœ…    â”‚
   â”‚  3. Rank                                â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Patient Engagement Agent               â”‚
   â”‚  [LLM: patient-message] âœ…              â”‚
   â”‚  Generate personalized message          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**LLM Calls: 3 per workflow**
1. Chat router (parse user input)
2. Provider scoring (rank providers)
3. Patient message (generate message)

---

## âœ… VALIDATION RESULTS

### Completeness: âœ… PASS
- All critical LLM calls have prompts
- Query handling covered by chat-router
- Patient response parsing not needed (URL-based)

### Architecture: âš ï¸ NEEDS SIMPLIFICATION
- **Remove:** `intent-classifier` and `entity-extractor` (redundant)
- **Keep:** `chat-router`, `provider-scoring`, `patient-message`
- **Add Later:** `clarification-generator` when needed

### Simplicity: âœ… PASS (After Cleanup)
- 3 core prompts (down from 5)
- Clear separation of concerns:
  - `chat-router` â†’ Parse user input
  - `provider-scoring` â†’ Rank providers
  - `patient-message` â†’ Generate messages
- Easy to understand and maintain

---

## ğŸ¯ RECOMMENDATIONS

### Immediate Actions

1. **Remove Redundant Prompts**
   ```yaml
   # DELETE from prompts/langfuse_prompts.yaml
   - healthcare-intent-classifier-v1  âŒ
   - healthcare-entity-extractor-v1   âŒ
   ```

2. **Keep Core Prompts**
   ```yaml
   # KEEP these 3
   - healthcare-chat-router-v1        âœ…
   - provider-scoring-prompt-v1       âœ…
   - patient-engagement-message-v1    âœ…
   ```

3. **Update .env**
   ```bash
   # Remove
   LANGFUSE_PROMPT_INTENT_CLASSIFIER=...  âŒ
   LANGFUSE_PROMPT_ENTITY_EXTRACTOR=...   âŒ
   
   # Keep
   LANGFUSE_PROMPT_CHAT_ROUTER=healthcare-chat-router-v1  âœ…
   LANGFUSE_PROMPT_PROVIDER_SCORER=provider-scoring-prompt-v1  âœ…
   LANGFUSE_PROMPT_PATIENT_MESSAGE=patient-engagement-message-v1  âœ…
   ```

### Future Enhancements (When Needed)

4. **Add Clarification Prompt** (if users are confused)
   ```yaml
   clarification-generator-v1:
     purpose: Handle ambiguous inputs
     example: "Did you mean Dr. Sarah or Sarah Miller?"
   ```

5. **Add Compliance Checker** (if rules get complex)
   ```yaml
   compliance-checker-v1:
     purpose: Interpret complex payer/POC rules
     example: "Can this provider treat Medicare patients?"
   ```

---

## ğŸ“Š Cost Comparison

### Current (5 prompts):
```
Per workflow:
- chat-router: 1 call
- intent-classifier: 1 call (redundant!)
- entity-extractor: 1 call (redundant!)
- provider-scoring: 1 call
- patient-message: 1 call

Total: 5 LLM calls per workflow
Cost: ~$0.05 per workflow
```

### Simplified (3 prompts):
```
Per workflow:
- chat-router: 1 call
- provider-scoring: 1 call
- patient-message: 1 call

Total: 3 LLM calls per workflow
Cost: ~$0.03 per workflow

Savings: 40% cheaper! ğŸ’°
```

---

## âœ… FINAL VERDICT

**Architecture:** âœ… Correct (after removing redundancy)  
**Completeness:** âœ… All critical paths covered  
**Simplicity:** âœ… 3 prompts is the sweet spot

**Action Required:** Remove 2 redundant prompts (intent-classifier, entity-extractor)

**Result:** Clean, simple, cost-effective architecture! ğŸ‰

