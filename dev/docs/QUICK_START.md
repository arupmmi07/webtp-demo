# ğŸš€ Quick Start Guide

## One Command to Start Everything

```bash
make dev
```

That's it! ğŸ‰

## What You'll See

```
ğŸ¤– LLM Configuration:
   Provider: LM Studio (Local)
   Model: openai/gpt-oss-20b
   API: http://localhost:1234/v1

âœ… API server started (PID: xxxxx)
âœ… Streamlit UI started (PID: xxxxx)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… All services running!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“± Application URLs:
   â€¢ Chat UI:    http://localhost:8501/
   â€¢ API Docs:   http://localhost:8000/docs
   â€¢ Calendar:   http://localhost:8000/schedule.html
   â€¢ Emails:     http://localhost:8000/emails.html

ğŸ¤– LLM Provider (Local Development):
   â€¢ Provider:   LM Studio
   â€¢ API:        http://localhost:1234/v1
   â€¢ Model:      openai/gpt-oss-20b
   â€¢ Status:     Connecting directly to LM Studio

ğŸ’¡ LM Studio Setup:
   1. Open LM Studio app
   2. Load model: openai/gpt-oss-20b
   3. Start 'Local Server' (port 1234)
   4. No login required - direct API access

ğŸ³ Docker Setup (Optional):
   To use LiteLLM proxy with Web UI instead:
   â€¢ Run: make docker-up
   â€¢ LiteLLM UI:  http://localhost:4000
   â€¢ Username:    admin
   â€¢ Password:    Set via LITELLM_MASTER_KEY (default: sk-1234)
```

## Two Modes of Operation

### Mode 1: Local Development (Default - `make dev`)
- âœ… **Direct connection to LM Studio**
- âœ… No proxy, no login
- âœ… Fast and simple
- âœ… Perfect for development

**LLM Access:**
- API: `http://localhost:1234/v1`
- No UI - direct API access
- No login required

### Mode 2: Docker with LiteLLM Proxy (`make docker-up`)
- âœ… **Full production-like setup**
- âœ… LiteLLM proxy with Web UI
- âœ… Multi-model support
- âœ… Cost tracking & monitoring

**LiteLLM Proxy Access:**
- URL: `http://localhost:4000`
- Username: `admin`
- Password: `sk-1234` (default, set via `LITELLM_MASTER_KEY`)

## Quick Commands

| Command | Description |
|---------|-------------|
| `make dev` | Start everything (local mode) |
| `make stop` | Stop all services |
| `make logs` | View logs |
| `make help` | Show all commands |
| `make docker-up` | Start with Docker + LiteLLM proxy |
| `make docker-down` | Stop Docker services |

## Prerequisites

### For Local Development (`make dev`)
1. **LM Studio** must be running
   - Download: https://lmstudio.ai/
   - Load model: `openai/gpt-oss-20b`
   - Start Local Server (port 1234)

2. **Python 3.9+** installed

3. **Virtual environment** set up
   ```bash
   make install
   ```

### For Docker Mode (`make docker-up`)
1. **Docker** installed and running
2. **Docker Compose** installed

## Testing the Setup

### 1. Check Services are Running
```bash
make status
```

### 2. Test the Workflow
1. Open Calendar: http://localhost:8000/schedule.html
2. Click "ğŸš« Mark Unavailable" on Dr. Sarah Johnson
3. Watch the AI workflow:
   - âœ… Intelligent provider matching
   - âœ… Personalized email generation
   - âœ… Automatic reassignment

### 3. Check Results
- View emails: http://localhost:8000/emails.html
- Check logs: `make logs`

## Troubleshooting

### "Connection error" when marking unavailable
**Problem:** LM Studio is not running or not accessible

**Solution:**
1. Open LM Studio
2. Load model: `openai/gpt-oss-20b`
3. Click "Start Server" (port 1234)
4. Restart services: `make stop && make dev`

### Ports already in use
**No problem!** `make dev` automatically kills processes on ports 8000 & 8501.

### Want to use cloud APIs instead?
Edit `scripts/start.sh` and change:
```bash
export LITELLM_BASE_URL="https://api.anthropic.com"
export LITELLM_API_KEY="your-api-key"
export LITELLM_DEFAULT_MODEL="claude-sonnet-4"
```

## What `make dev` Does Automatically

1. âœ… Kills existing processes (ports 8000, 8501)
2. âœ… Resets demo data to initial state
3. âœ… Exports LM Studio configuration
4. âœ… Starts API server with LLM enabled
5. âœ… Starts UI server
6. âœ… Shows all URLs and credentials

**No manual configuration needed!**

## Help

```bash
make help
```

Shows complete list of commands and URLs.

---

**Remember:** Just run `make dev` and you're good to go! ğŸš€

