# âœ… `make dev` - ONE COMMAND SETUP

## Summary
**You can now just run `make dev` and everything works!**

## What Was Fixed

### Problem
When running `make dev` â†’ marking provider unavailable â†’ system used **rule-based fallback** instead of **LLM**.

### Root Cause
Agents weren't configured to connect to LM Studio automatically.

### Solution
Updated 4 files to enable LLM by default:

1. **`scripts/start.sh`** - Exports LM Studio env vars automatically
2. **`agents/smart_scheduling_agent.py`** - Defaults to LM Studio
3. **`agents/patient_engagement_agent.py`** - Defaults to LM Studio  
4. **`config/llm_settings.py`** - Defaults to LM Studio

## How to Use

### 1. Start LM Studio
- Open LM Studio app
- Load model: `openai/gpt-oss-20b`
- Start Local Server (port 1234)

### 2. Run One Command
```bash
make dev
```

**That's it!** âœ¨

## What `make dev` Does

1. âœ… **Kills existing processes** on ports 8000 & 8501
2. âœ… **Resets demo data** to initial state
3. âœ… **Exports LM Studio config** automatically:
   ```bash
   export LITELLM_BASE_URL="http://localhost:1234/v1"
   export LITELLM_API_KEY="lm-studio"
   export LITELLM_DEFAULT_MODEL="openai/gpt-oss-20b"
   ```
4. âœ… **Starts API & UI** with LLM enabled

## Verification

### You'll see this output:
```
ğŸ¤– LLM Configuration:
   Provider: LM Studio (Local)
   Model: openai/gpt-oss-20b
   API: http://localhost:1234/v1

âœ… API server started (PID: xxxxx)
   URL: http://localhost:8000

âœ… Streamlit UI started (PID: xxxxx)
   URL: http://localhost:8501
```

### Test the workflow:
1. Open: http://localhost:8000/schedule.html
2. Click **"ğŸš« Mark Unavailable"** on Dr. Sarah Johnson
3. Watch the magic:
   - âœ… LLM generates **personalized emails**
   - âœ… LLM performs **intelligent provider matching**
   - âœ… **NO** "Falling back to template" errors

## Fallback Behavior

If LM Studio is **not running**, agents will gracefully fall back to MockLLM and show:
```
[AGENT] Warning: LiteLLM configuration failed
[AGENT] Falling back to Mock LLM
```

To fix: Just start LM Studio and restart services (`make dev`).

## Files Modified

| File | Change |
|------|--------|
| `scripts/start.sh` | Added LM Studio env var exports |
| `agents/smart_scheduling_agent.py` | Changed default from no config â†’ LM Studio |
| `agents/patient_engagement_agent.py` | Changed default from `localhost:4000` â†’ `localhost:1234/v1` |
| `config/llm_settings.py` | Changed default from `localhost:4000` â†’ `localhost:1234/v1` |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  make dev                                       â”‚
â”‚  â””â”€ scripts/start.sh                            â”‚
â”‚     â”œâ”€ Export LITELLM_BASE_URL, API_KEY, MODEL  â”‚
â”‚     â”œâ”€ Kill ports 8000, 8501                    â”‚
â”‚     â””â”€ Start API & UI servers                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  agents/smart_scheduling_agent.py               â”‚
â”‚  agents/patient_engagement_agent.py             â”‚
â”‚  â””â”€ Read env vars (or use LM Studio defaults)  â”‚
â”‚     â””â”€ Initialize LiteLLMAdapter                â”‚
â”‚        â””â”€ Connect to http://localhost:1234/v1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LM Studio (Local LLM Server)                   â”‚
â”‚  â””â”€ Model: openai/gpt-oss-20b                   â”‚
â”‚     â””â”€ API: http://localhost:1234/v1            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## No More Manual Setup! ğŸ‰

Before:
- âŒ Export env vars manually
- âŒ Configure each agent separately
- âŒ Remember to kill ports
- âŒ 5+ steps to get started

After:
- âœ… **ONE COMMAND: `make dev`**
- âœ… Everything configured automatically
- âœ… Ready to demo in seconds

---

**Remember:** Just run `make dev` - that's it! ğŸš€

